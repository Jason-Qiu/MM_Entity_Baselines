{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7438c98e-8b1d-44ed-9840-64a9827cc6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using pad_token, but it is not set yet.\n",
      "/data/home/jielinq/.cache/huggingface/modules/transformers_modules/anas-awadalla/mpt-1b-redpajama-200b/bfa38d4f431e091fe599d7b4cdb62972532f3c7c/attention.py:289: UserWarning: Using `attn_impl: torch`. If your model does not use `alibi` or `prefix_lm` we recommend using `attn_impl: flash` otherwise we recommend using `attn_impl: triton`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n",
      "Flamingo model initialized with 1046992944 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "from open_flamingo import create_model_and_transforms\n",
    "\n",
    "model, image_processor, tokenizer = create_model_and_transforms(\n",
    "    clip_vision_encoder_path=\"ViT-L-14\",\n",
    "    clip_vision_encoder_pretrained=\"openai\",\n",
    "    lang_encoder_path=\"anas-awadalla/mpt-1b-redpajama-200b\",\n",
    "    tokenizer_path=\"anas-awadalla/mpt-1b-redpajama-200b\",\n",
    "    cross_attn_every_n_layers=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b5c591-3294-49ba-9927-7ee354027d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "from pycocoevalcap.cider import cider\n",
    "from pycocoevalcap.spice import spice\n",
    "from bert_score import score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74accac8-db6e-499d-be0b-9757278a376d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['vision_encoder.class_embedding', 'vision_encoder.positional_embedding', 'vision_encoder.proj', 'vision_encoder.conv1.weight', 'vision_encoder.ln_pre.weight', 'vision_encoder.ln_pre.bias', 'vision_encoder.transformer.resblocks.0.ln_1.weight', 'vision_encoder.transformer.resblocks.0.ln_1.bias', 'vision_encoder.transformer.resblocks.0.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.0.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.0.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.0.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.0.ln_2.weight', 'vision_encoder.transformer.resblocks.0.ln_2.bias', 'vision_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.1.ln_1.weight', 'vision_encoder.transformer.resblocks.1.ln_1.bias', 'vision_encoder.transformer.resblocks.1.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.1.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.1.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.1.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.1.ln_2.weight', 'vision_encoder.transformer.resblocks.1.ln_2.bias', 'vision_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.2.ln_1.weight', 'vision_encoder.transformer.resblocks.2.ln_1.bias', 'vision_encoder.transformer.resblocks.2.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.2.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.2.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.2.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.2.ln_2.weight', 'vision_encoder.transformer.resblocks.2.ln_2.bias', 'vision_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.3.ln_1.weight', 'vision_encoder.transformer.resblocks.3.ln_1.bias', 'vision_encoder.transformer.resblocks.3.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.3.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.3.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.3.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.3.ln_2.weight', 'vision_encoder.transformer.resblocks.3.ln_2.bias', 'vision_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.4.ln_1.weight', 'vision_encoder.transformer.resblocks.4.ln_1.bias', 'vision_encoder.transformer.resblocks.4.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.4.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.4.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.4.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.4.ln_2.weight', 'vision_encoder.transformer.resblocks.4.ln_2.bias', 'vision_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.5.ln_1.weight', 'vision_encoder.transformer.resblocks.5.ln_1.bias', 'vision_encoder.transformer.resblocks.5.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.5.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.5.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.5.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.5.ln_2.weight', 'vision_encoder.transformer.resblocks.5.ln_2.bias', 'vision_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.6.ln_1.weight', 'vision_encoder.transformer.resblocks.6.ln_1.bias', 'vision_encoder.transformer.resblocks.6.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.6.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.6.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.6.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.6.ln_2.weight', 'vision_encoder.transformer.resblocks.6.ln_2.bias', 'vision_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.7.ln_1.weight', 'vision_encoder.transformer.resblocks.7.ln_1.bias', 'vision_encoder.transformer.resblocks.7.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.7.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.7.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.7.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.7.ln_2.weight', 'vision_encoder.transformer.resblocks.7.ln_2.bias', 'vision_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.8.ln_1.weight', 'vision_encoder.transformer.resblocks.8.ln_1.bias', 'vision_encoder.transformer.resblocks.8.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.8.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.8.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.8.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.8.ln_2.weight', 'vision_encoder.transformer.resblocks.8.ln_2.bias', 'vision_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.9.ln_1.weight', 'vision_encoder.transformer.resblocks.9.ln_1.bias', 'vision_encoder.transformer.resblocks.9.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.9.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.9.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.9.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.9.ln_2.weight', 'vision_encoder.transformer.resblocks.9.ln_2.bias', 'vision_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.10.ln_1.weight', 'vision_encoder.transformer.resblocks.10.ln_1.bias', 'vision_encoder.transformer.resblocks.10.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.10.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.10.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.10.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.10.ln_2.weight', 'vision_encoder.transformer.resblocks.10.ln_2.bias', 'vision_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.11.ln_1.weight', 'vision_encoder.transformer.resblocks.11.ln_1.bias', 'vision_encoder.transformer.resblocks.11.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.11.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.11.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.11.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.11.ln_2.weight', 'vision_encoder.transformer.resblocks.11.ln_2.bias', 'vision_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.12.ln_1.weight', 'vision_encoder.transformer.resblocks.12.ln_1.bias', 'vision_encoder.transformer.resblocks.12.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.12.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.12.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.12.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.12.ln_2.weight', 'vision_encoder.transformer.resblocks.12.ln_2.bias', 'vision_encoder.transformer.resblocks.12.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.12.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.12.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.12.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.13.ln_1.weight', 'vision_encoder.transformer.resblocks.13.ln_1.bias', 'vision_encoder.transformer.resblocks.13.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.13.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.13.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.13.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.13.ln_2.weight', 'vision_encoder.transformer.resblocks.13.ln_2.bias', 'vision_encoder.transformer.resblocks.13.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.13.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.13.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.13.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.14.ln_1.weight', 'vision_encoder.transformer.resblocks.14.ln_1.bias', 'vision_encoder.transformer.resblocks.14.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.14.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.14.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.14.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.14.ln_2.weight', 'vision_encoder.transformer.resblocks.14.ln_2.bias', 'vision_encoder.transformer.resblocks.14.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.14.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.14.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.14.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.15.ln_1.weight', 'vision_encoder.transformer.resblocks.15.ln_1.bias', 'vision_encoder.transformer.resblocks.15.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.15.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.15.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.15.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.15.ln_2.weight', 'vision_encoder.transformer.resblocks.15.ln_2.bias', 'vision_encoder.transformer.resblocks.15.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.15.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.15.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.15.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.16.ln_1.weight', 'vision_encoder.transformer.resblocks.16.ln_1.bias', 'vision_encoder.transformer.resblocks.16.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.16.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.16.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.16.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.16.ln_2.weight', 'vision_encoder.transformer.resblocks.16.ln_2.bias', 'vision_encoder.transformer.resblocks.16.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.16.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.16.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.16.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.17.ln_1.weight', 'vision_encoder.transformer.resblocks.17.ln_1.bias', 'vision_encoder.transformer.resblocks.17.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.17.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.17.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.17.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.17.ln_2.weight', 'vision_encoder.transformer.resblocks.17.ln_2.bias', 'vision_encoder.transformer.resblocks.17.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.17.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.17.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.17.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.18.ln_1.weight', 'vision_encoder.transformer.resblocks.18.ln_1.bias', 'vision_encoder.transformer.resblocks.18.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.18.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.18.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.18.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.18.ln_2.weight', 'vision_encoder.transformer.resblocks.18.ln_2.bias', 'vision_encoder.transformer.resblocks.18.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.18.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.18.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.18.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.19.ln_1.weight', 'vision_encoder.transformer.resblocks.19.ln_1.bias', 'vision_encoder.transformer.resblocks.19.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.19.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.19.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.19.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.19.ln_2.weight', 'vision_encoder.transformer.resblocks.19.ln_2.bias', 'vision_encoder.transformer.resblocks.19.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.19.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.19.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.19.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.20.ln_1.weight', 'vision_encoder.transformer.resblocks.20.ln_1.bias', 'vision_encoder.transformer.resblocks.20.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.20.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.20.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.20.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.20.ln_2.weight', 'vision_encoder.transformer.resblocks.20.ln_2.bias', 'vision_encoder.transformer.resblocks.20.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.20.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.20.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.20.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.21.ln_1.weight', 'vision_encoder.transformer.resblocks.21.ln_1.bias', 'vision_encoder.transformer.resblocks.21.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.21.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.21.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.21.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.21.ln_2.weight', 'vision_encoder.transformer.resblocks.21.ln_2.bias', 'vision_encoder.transformer.resblocks.21.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.21.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.21.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.21.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.22.ln_1.weight', 'vision_encoder.transformer.resblocks.22.ln_1.bias', 'vision_encoder.transformer.resblocks.22.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.22.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.22.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.22.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.22.ln_2.weight', 'vision_encoder.transformer.resblocks.22.ln_2.bias', 'vision_encoder.transformer.resblocks.22.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.22.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.22.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.22.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.23.ln_1.weight', 'vision_encoder.transformer.resblocks.23.ln_1.bias', 'vision_encoder.transformer.resblocks.23.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.23.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.23.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.23.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.23.ln_2.weight', 'vision_encoder.transformer.resblocks.23.ln_2.bias', 'vision_encoder.transformer.resblocks.23.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.23.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.23.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.23.mlp.c_proj.bias', 'vision_encoder.ln_post.weight', 'vision_encoder.ln_post.bias', 'lang_encoder.transformer.blocks.0.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.ln_1.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.attn.q_ln.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.attn.k_ln.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.ln_2.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.mlp.mlp_up.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.mlp.mlp_down.weight', 'lang_encoder.transformer.ln_f.weight', 'lang_encoder.old_decoder_blocks.0.ln_1.weight', 'lang_encoder.old_decoder_blocks.0.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.0.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.0.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.0.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.0.ln_2.weight', 'lang_encoder.old_decoder_blocks.0.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.0.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.1.ln_1.weight', 'lang_encoder.old_decoder_blocks.1.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.1.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.1.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.1.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.1.ln_2.weight', 'lang_encoder.old_decoder_blocks.1.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.1.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.2.ln_1.weight', 'lang_encoder.old_decoder_blocks.2.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.2.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.2.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.2.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.2.ln_2.weight', 'lang_encoder.old_decoder_blocks.2.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.2.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.3.ln_1.weight', 'lang_encoder.old_decoder_blocks.3.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.3.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.3.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.3.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.3.ln_2.weight', 'lang_encoder.old_decoder_blocks.3.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.3.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.4.ln_1.weight', 'lang_encoder.old_decoder_blocks.4.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.4.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.4.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.4.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.4.ln_2.weight', 'lang_encoder.old_decoder_blocks.4.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.4.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.5.ln_1.weight', 'lang_encoder.old_decoder_blocks.5.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.5.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.5.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.5.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.5.ln_2.weight', 'lang_encoder.old_decoder_blocks.5.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.5.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.6.ln_1.weight', 'lang_encoder.old_decoder_blocks.6.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.6.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.6.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.6.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.6.ln_2.weight', 'lang_encoder.old_decoder_blocks.6.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.6.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.7.ln_1.weight', 'lang_encoder.old_decoder_blocks.7.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.7.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.7.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.7.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.7.ln_2.weight', 'lang_encoder.old_decoder_blocks.7.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.7.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.8.ln_1.weight', 'lang_encoder.old_decoder_blocks.8.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.8.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.8.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.8.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.8.ln_2.weight', 'lang_encoder.old_decoder_blocks.8.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.8.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.9.ln_1.weight', 'lang_encoder.old_decoder_blocks.9.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.9.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.9.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.9.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.9.ln_2.weight', 'lang_encoder.old_decoder_blocks.9.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.9.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.10.ln_1.weight', 'lang_encoder.old_decoder_blocks.10.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.10.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.10.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.10.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.10.ln_2.weight', 'lang_encoder.old_decoder_blocks.10.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.10.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.11.ln_1.weight', 'lang_encoder.old_decoder_blocks.11.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.11.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.11.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.11.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.11.ln_2.weight', 'lang_encoder.old_decoder_blocks.11.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.11.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.12.ln_1.weight', 'lang_encoder.old_decoder_blocks.12.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.12.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.12.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.12.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.12.ln_2.weight', 'lang_encoder.old_decoder_blocks.12.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.12.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.13.ln_1.weight', 'lang_encoder.old_decoder_blocks.13.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.13.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.13.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.13.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.13.ln_2.weight', 'lang_encoder.old_decoder_blocks.13.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.13.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.14.ln_1.weight', 'lang_encoder.old_decoder_blocks.14.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.14.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.14.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.14.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.14.ln_2.weight', 'lang_encoder.old_decoder_blocks.14.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.14.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.15.ln_1.weight', 'lang_encoder.old_decoder_blocks.15.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.15.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.15.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.15.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.15.ln_2.weight', 'lang_encoder.old_decoder_blocks.15.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.15.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.16.ln_1.weight', 'lang_encoder.old_decoder_blocks.16.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.16.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.16.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.16.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.16.ln_2.weight', 'lang_encoder.old_decoder_blocks.16.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.16.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.17.ln_1.weight', 'lang_encoder.old_decoder_blocks.17.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.17.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.17.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.17.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.17.ln_2.weight', 'lang_encoder.old_decoder_blocks.17.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.17.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.18.ln_1.weight', 'lang_encoder.old_decoder_blocks.18.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.18.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.18.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.18.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.18.ln_2.weight', 'lang_encoder.old_decoder_blocks.18.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.18.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.19.ln_1.weight', 'lang_encoder.old_decoder_blocks.19.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.19.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.19.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.19.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.19.ln_2.weight', 'lang_encoder.old_decoder_blocks.19.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.19.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.20.ln_1.weight', 'lang_encoder.old_decoder_blocks.20.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.20.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.20.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.20.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.20.ln_2.weight', 'lang_encoder.old_decoder_blocks.20.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.20.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.21.ln_1.weight', 'lang_encoder.old_decoder_blocks.21.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.21.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.21.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.21.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.21.ln_2.weight', 'lang_encoder.old_decoder_blocks.21.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.21.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.22.ln_1.weight', 'lang_encoder.old_decoder_blocks.22.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.22.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.22.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.22.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.22.ln_2.weight', 'lang_encoder.old_decoder_blocks.22.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.22.mlp.mlp_down.weight', 'lang_encoder.old_decoder_blocks.23.ln_1.weight', 'lang_encoder.old_decoder_blocks.23.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.23.attn.q_ln.weight', 'lang_encoder.old_decoder_blocks.23.attn.k_ln.weight', 'lang_encoder.old_decoder_blocks.23.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.23.ln_2.weight', 'lang_encoder.old_decoder_blocks.23.mlp.mlp_up.weight', 'lang_encoder.old_decoder_blocks.23.mlp.mlp_down.weight', 'lang_encoder.gated_cross_attn_layers.0.attn_gate', 'lang_encoder.gated_cross_attn_layers.0.ff_gate', 'lang_encoder.gated_cross_attn_layers.0.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.0.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.0.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.0.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.0.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.0.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.0.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.0.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.0.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.1.attn_gate', 'lang_encoder.gated_cross_attn_layers.1.ff_gate', 'lang_encoder.gated_cross_attn_layers.1.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.1.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.1.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.1.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.1.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.1.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.1.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.1.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.1.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.2.attn_gate', 'lang_encoder.gated_cross_attn_layers.2.ff_gate', 'lang_encoder.gated_cross_attn_layers.2.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.2.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.2.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.2.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.2.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.2.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.2.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.2.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.2.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.3.attn_gate', 'lang_encoder.gated_cross_attn_layers.3.ff_gate', 'lang_encoder.gated_cross_attn_layers.3.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.3.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.3.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.4.attn_gate', 'lang_encoder.gated_cross_attn_layers.4.ff_gate', 'lang_encoder.gated_cross_attn_layers.4.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.4.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.4.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.4.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.4.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.4.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.4.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.4.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.4.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.5.attn_gate', 'lang_encoder.gated_cross_attn_layers.5.ff_gate', 'lang_encoder.gated_cross_attn_layers.5.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.5.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.5.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.5.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.5.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.5.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.5.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.5.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.5.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.6.attn_gate', 'lang_encoder.gated_cross_attn_layers.6.ff_gate', 'lang_encoder.gated_cross_attn_layers.6.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.6.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.6.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.6.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.6.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.6.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.6.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.6.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.6.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.7.attn_gate', 'lang_encoder.gated_cross_attn_layers.7.ff_gate', 'lang_encoder.gated_cross_attn_layers.7.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.7.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.7.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.8.attn_gate', 'lang_encoder.gated_cross_attn_layers.8.ff_gate', 'lang_encoder.gated_cross_attn_layers.8.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.8.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.8.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.8.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.8.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.8.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.8.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.8.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.8.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.9.attn_gate', 'lang_encoder.gated_cross_attn_layers.9.ff_gate', 'lang_encoder.gated_cross_attn_layers.9.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.9.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.9.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.9.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.9.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.9.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.9.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.9.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.9.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.10.attn_gate', 'lang_encoder.gated_cross_attn_layers.10.ff_gate', 'lang_encoder.gated_cross_attn_layers.10.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.10.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.10.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.10.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.10.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.10.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.10.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.10.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.10.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.11.attn_gate', 'lang_encoder.gated_cross_attn_layers.11.ff_gate', 'lang_encoder.gated_cross_attn_layers.11.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.11.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.11.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.12.attn_gate', 'lang_encoder.gated_cross_attn_layers.12.ff_gate', 'lang_encoder.gated_cross_attn_layers.12.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.12.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.12.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.12.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.12.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.12.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.12.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.12.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.12.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.13.attn_gate', 'lang_encoder.gated_cross_attn_layers.13.ff_gate', 'lang_encoder.gated_cross_attn_layers.13.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.13.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.13.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.13.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.13.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.13.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.13.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.13.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.13.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.14.attn_gate', 'lang_encoder.gated_cross_attn_layers.14.ff_gate', 'lang_encoder.gated_cross_attn_layers.14.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.14.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.14.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.14.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.14.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.14.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.14.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.14.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.14.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.15.attn_gate', 'lang_encoder.gated_cross_attn_layers.15.ff_gate', 'lang_encoder.gated_cross_attn_layers.15.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.15.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.15.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.16.attn_gate', 'lang_encoder.gated_cross_attn_layers.16.ff_gate', 'lang_encoder.gated_cross_attn_layers.16.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.16.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.16.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.16.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.16.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.16.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.16.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.16.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.16.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.17.attn_gate', 'lang_encoder.gated_cross_attn_layers.17.ff_gate', 'lang_encoder.gated_cross_attn_layers.17.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.17.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.17.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.17.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.17.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.17.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.17.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.17.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.17.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.18.attn_gate', 'lang_encoder.gated_cross_attn_layers.18.ff_gate', 'lang_encoder.gated_cross_attn_layers.18.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.18.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.18.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.18.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.18.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.18.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.18.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.18.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.18.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.19.attn_gate', 'lang_encoder.gated_cross_attn_layers.19.ff_gate', 'lang_encoder.gated_cross_attn_layers.19.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.19.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.19.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.20.attn_gate', 'lang_encoder.gated_cross_attn_layers.20.ff_gate', 'lang_encoder.gated_cross_attn_layers.20.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.20.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.20.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.20.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.20.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.20.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.20.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.20.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.20.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.21.attn_gate', 'lang_encoder.gated_cross_attn_layers.21.ff_gate', 'lang_encoder.gated_cross_attn_layers.21.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.21.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.21.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.21.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.21.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.21.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.21.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.21.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.21.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.22.attn_gate', 'lang_encoder.gated_cross_attn_layers.22.ff_gate', 'lang_encoder.gated_cross_attn_layers.22.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.22.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.22.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.22.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.22.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.22.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.22.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.22.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.22.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.23.attn_gate', 'lang_encoder.gated_cross_attn_layers.23.ff_gate', 'lang_encoder.gated_cross_attn_layers.23.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.23.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.23.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.3.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = hf_hub_download(\"openflamingo/OpenFlamingo-3B-vitl-mpt1b\", \"checkpoint.pt\")\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc508b15-8fc4-4be9-a951-0d53948343db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  <image>An image of two cats.<|endofchunk|><image>An image of a bathroom sink.<|endofchunk|><image>An image of a buffet table.<|endofchunk|>\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "Step 1: Load images\n",
    "\"\"\"\n",
    "demo_image_one = Image.open(\n",
    "    requests.get(\n",
    "        \"http://images.cocodataset.org/val2017/000000039769.jpg\", stream=True\n",
    "    ).raw\n",
    ")\n",
    "\n",
    "demo_image_two = Image.open(\n",
    "    requests.get(\n",
    "        \"http://images.cocodataset.org/test-stuff2017/000000028137.jpg\",\n",
    "        stream=True\n",
    "    ).raw\n",
    ")\n",
    "\n",
    "query_image = Image.open(\n",
    "    requests.get(\n",
    "        \"http://images.cocodataset.org/test-stuff2017/000000028352.jpg\", \n",
    "        stream=True\n",
    "    ).raw\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Step 2: Preprocessing images\n",
    "Details: For OpenFlamingo, we expect the image to be a torch tensor of shape \n",
    " batch_size x num_media x num_frames x channels x height x width. \n",
    " In this case batch_size = 1, num_media = 3, num_frames = 1,\n",
    " channels = 3, height = 224, width = 224.\n",
    "\"\"\"\n",
    "vision_x = [image_processor(demo_image_one).unsqueeze(0), image_processor(demo_image_two).unsqueeze(0), image_processor(query_image).unsqueeze(0)]\n",
    "vision_x = torch.cat(vision_x, dim=0)\n",
    "vision_x = vision_x.unsqueeze(1).unsqueeze(0)\n",
    "\n",
    "\"\"\"\n",
    "Step 3: Preprocessing text\n",
    "Details: In the text we expect an <image> special token to indicate where an image is.\n",
    " We also expect an <|endofchunk|> special token to indicate the end of the text \n",
    " portion associated with an image.\n",
    "\"\"\"\n",
    "tokenizer.padding_side = \"left\" # For generation padding tokens should be on the left\n",
    "lang_x = tokenizer(\n",
    "    [\"<image>An image of two cats.<|endofchunk|><image>An image of a bathroom sink.<|endofchunk|><image>An image of\"],\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Step 4: Generate text\n",
    "\"\"\"\n",
    "generated_text = model.generate(\n",
    "    vision_x=vision_x,\n",
    "    lang_x=lang_x[\"input_ids\"],\n",
    "    attention_mask=lang_x[\"attention_mask\"],\n",
    "    max_new_tokens=20,\n",
    "    num_beams=3,\n",
    ")\n",
    "\n",
    "print(\"Generated text: \", tokenizer.decode(generated_text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a480ec90-6c56-4f19-84a0-bd171c0c664a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An image of a buffet table'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_text[0])[98:-15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a8289c4-1135-4097-9219-97758a9a91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(image_path, question):\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Step 1: Load images\n",
    "    \"\"\"\n",
    "    demo_image_one = Image.open(\n",
    "        requests.get(\n",
    "            \"http://images.cocodataset.org/val2017/000000039769.jpg\", stream=True\n",
    "        ).raw\n",
    "    )\n",
    "\n",
    "    demo_image_two = Image.open(\n",
    "        requests.get(\n",
    "            \"http://images.cocodataset.org/test-stuff2017/000000028137.jpg\",\n",
    "            stream=True\n",
    "        ).raw\n",
    "    )\n",
    "\n",
    "    query_image = Image.open(image_path)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Step 2: Preprocessing images\n",
    "    Details: For OpenFlamingo, we expect the image to be a torch tensor of shape \n",
    "     batch_size x num_media x num_frames x channels x height x width. \n",
    "     In this case batch_size = 1, num_media = 3, num_frames = 1,\n",
    "     channels = 3, height = 224, width = 224.\n",
    "    \"\"\"\n",
    "    vision_x = [image_processor(demo_image_one).unsqueeze(0), image_processor(demo_image_two).unsqueeze(0), image_processor(query_image).unsqueeze(0)]\n",
    "    vision_x = torch.cat(vision_x, dim=0)\n",
    "    vision_x = vision_x.unsqueeze(1).unsqueeze(0)\n",
    "\n",
    "    \"\"\"\n",
    "    Step 3: Preprocessing text\n",
    "    Details: In the text we expect an <image> special token to indicate where an image is.\n",
    "     We also expect an <|endofchunk|> special token to indicate the end of the text \n",
    "     portion associated with an image.\n",
    "    \"\"\"\n",
    "    tokenizer.padding_side = \"left\" # For generation padding tokens should be on the left\n",
    "    lang_x = tokenizer(\n",
    "        [\"<image>An image of two cats.<|endofchunk|><image>An image of a bathroom sink.<|endofchunk|><image>%s\"%question],\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Step 4: Generate text\n",
    "    \"\"\"\n",
    "    generated_text = model.generate(\n",
    "        vision_x=vision_x,\n",
    "        lang_x=lang_x[\"input_ids\"],\n",
    "        attention_mask=lang_x[\"attention_mask\"],\n",
    "        max_new_tokens=20,\n",
    "        num_beams=3,\n",
    "    )\n",
    "\n",
    "    #print(\"Generated text: \", tokenizer.decode(generated_text[0]))\n",
    "    \n",
    "    answer = tokenizer.decode(generated_text[0])[98:-15]\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae29742c-bb40-4d79-926d-c039d928eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(sentence):\n",
    "    return sentence.split(' ')\n",
    "\n",
    "def Rouge(GT_caption, generated_caption): # returns list of all rouge_n needed in (precision,recall,fmeasure) for each\n",
    "    res = []\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
    "    output = scorer.score(GT_caption, generated_caption)\n",
    "    for r in output:\n",
    "        score = output[r]\n",
    "        res.append((score.precision, score.recall, score.fmeasure))\n",
    "    return res[0][2], res[1][2], res[2][2]\n",
    "\n",
    "def Bleu_4(GT_caption, generated_caption):\n",
    "    GT_words = split_words(GT_caption)\n",
    "    gen_words = split_words(generated_caption)\n",
    "    weights = (1./4., 1./4., 1./4., 1./4.)\n",
    "    return corpus_bleu([[GT_words]], [gen_words], weights)\n",
    "\n",
    "def METEOR(GT_caption, generated_caption):\n",
    "    GT_words = split_words(GT_caption)\n",
    "    gen_words = split_words(generated_caption)\n",
    "    return meteor_score([GT_words], gen_words)\n",
    "\n",
    "def CIDEr(GT_caption, generated_caption):\n",
    "    scorer = cider.Cider()\n",
    "    return scorer.compute_score({0:[GT_caption]}, {0:[generated_caption]})[0]\n",
    "\n",
    "def SPICE(GT_caption, generated_caption):\n",
    "    scorer = spice.Spice()\n",
    "    return scorer.compute_score({0:[GT_caption]}, {0:[generated_caption]})[0]\n",
    "\n",
    "def BertScore(GT_caption, generated_caption):\n",
    "    P, R, F1 = score([generated_caption], [GT_caption], lang=\"en\", verbose=True)\n",
    "    #return P.tolist()[0], R.tolist()[0], F1.tolist()[0]\n",
    "    return F1.tolist()[0]\n",
    "\n",
    "def acc_full(GT_caption, generated_caption):\n",
    "    GT_caption = GT_caption.lower()\n",
    "    generated_caption = generated_caption.lower()\n",
    "    return int(GT_caption in generated_caption)\n",
    "\n",
    "def acc_part(GT_caption, generated_caption):\n",
    "    GT_words = split_words(GT_caption.lower())\n",
    "    generated_caption = generated_caption.lower()\n",
    "    \n",
    "    in_generated = 0\n",
    "    for word in GT_words:\n",
    "        if word in generated_caption:\n",
    "            in_generated += 1\n",
    "            \n",
    "    return in_generated / len(GT_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f425343d-d7a5-4daf-b100-ea8df47b9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_evaluation(GT_caption, generated_caption):\n",
    "    rouge1, rouge2, rougeL = Rouge(GT_caption, generated_caption)\n",
    "    bleu4 = Bleu_4(GT_caption, generated_caption)\n",
    "    meteor = METEOR(GT_caption, generated_caption)\n",
    "    cider= CIDEr(GT_caption, generated_caption)\n",
    "    spice = SPICE(GT_caption, generated_caption)\n",
    "    bertscore = BertScore(GT_caption, generated_caption)\n",
    "    \n",
    "    return rouge1, rouge2, rougeL, bleu4, meteor, cider, spice, bertscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1238eeb-a433-4be0-bae3-dbd5983cb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tsv = pd.read_csv(\"landmark_all.tsv\", sep='\\t', encoding='utf-8')\n",
    "\n",
    "df_results = pd.DataFrame(columns=['GT_answer', 'generated_answer','rouge1', 'rouge2', 'rougeL', 'bleu4', 'meteor', 'cider', 'spice', 'bertscore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830465ef-1271-48bb-9d67-fd166f6f0537",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 717.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 462.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.15 sentences/sec\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 725.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 65.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 659.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.38 sentences/sec\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.246 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.807 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 65.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 562.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 47.08 sentences/sec\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 66.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 629.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 50.29 sentences/sec\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.650 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.257 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 66.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 772.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 47.31 sentences/sec\n",
      "250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 712.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 644.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 51.23 sentences/sec\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [1.182 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.672 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 62.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 523.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 45.43 sentences/sec\n",
      "350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 762.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 63.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 562.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 46.32 sentences/sec\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.544 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.994 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 68.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 629.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 51.32 sentences/sec\n",
      "450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 764.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 62.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 498.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 46.55 sentences/sec\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.411 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.109 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 65.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 618.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 48.83 sentences/sec\n",
      "550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 717.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 68.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 669.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 51.62 sentences/sec\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [0.461 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.872 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 426.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.26 sentences/sec\n",
      "650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 711.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 65.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 622.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.23 sentences/sec\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [6.838 seconds]\n",
      "Error: Could not cache item to /data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"A: The Acropolis of Athens has a long and storied history dating back to the 4th millennium BCE Over time it has been home to numerous settlements and religious structures including the iconic Parthenon In the 5th century BCE under the leadership of Pericles the site was transformed into a monumental complex dedicated to the goddess Athena In the subsequent centuries the Acropolis fell victim to various attacks and natural disasters resulting in significant damage to its buildings Today it stands as a testament to the rich cultural heritage of Ancient Greece and a symbol of democracy and Western civilization\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 52.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 587.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 40.95 sentences/sec\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [6.872 seconds]\n",
      "Error: Could not cache item to /data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"A: The Acropolis of Athens has a long and storied history dating back to the 4th millennium BCE Over time it has been home to numerous settlements and religious structures including the iconic Parthenon In the 5th century BCE under the leadership of Pericles the site was transformed into a monumental complex dedicated to the goddess Athena In the subsequent centuries the Acropolis fell victim to various attacks and natural disasters resulting in significant damage to its buildings Today it stands as a testament to the rich cultural heritage of Ancient Greece and a symbol of democracy and Western civilization\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 54.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 609.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 43.06 sentences/sec\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.679 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.121 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.196 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 66.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 605.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.03 sentences/sec\n",
      "850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 723.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 609.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.34 sentences/sec\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.359 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.711 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 635.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 51.14 sentences/sec\n",
      "950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 700.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 691.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 48.97 sentences/sec\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.403 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.831 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 68.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 697.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 30.97 sentences/sec\n",
      "1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 802.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 609.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 50.59 sentences/sec\n",
      "1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [2.70 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.498 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 58.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 492.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.14 sentences/sec\n",
      "1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 716.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 63.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 617.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 48.14 sentences/sec\n",
      "1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [1.828 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.686 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 61.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 598.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.67 sentences/sec\n",
      "1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 717.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 60.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 617.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 46.26 sentences/sec\n",
      "1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.492 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.045 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 64.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 656.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 48.44 sentences/sec\n",
      "1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 719.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 60.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 452.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 45.00 sentences/sec\n",
      "1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.263 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.793 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 60.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 426.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.68 sentences/sec\n",
      "1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 715.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 66.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 749.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 47.76 sentences/sec\n",
      "1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.415 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.947 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 639.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 51.01 sentences/sec\n",
      "1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 716.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 64.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 638.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 48.67 sentences/sec\n",
      "1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.371 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.101 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.100 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 65.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 612.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.66 sentences/sec\n",
      "1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 719.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 69.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 690.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 52.19 sentences/sec\n",
      "1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.328 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.915 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 65.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 612.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.34 sentences/sec\n",
      "1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 66.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 647.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 50.32 sentences/sec\n",
      "1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [5.684 seconds]\n",
      "Error: Could not cache item to /data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"The construction of Amalienborg Palace represents a significant moment in Danish history as it symbolizes the transition from absolutism to constitutional monarchy after the fire at Christiansborg Palace This event marked the beginning of a new era for Denmark where the power of the king was limited by a written constitution creating a balance between the executive legislative and judicial branches of government Additionally the design of the palace itself reflects this shift towards modernity incorporating elements of neoclassical architecture while still paying homage to traditional Danish styles\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.10 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 55.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 428.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 41.70 sentences/sec\n",
      "1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [5.779 seconds]\n",
      "Error: Could not cache item to /data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"The construction of Amalienborg Palace represents a significant moment in Danish history as it symbolizes the transition from absolutism to constitutional monarchy after the fire at Christiansborg Palace This event marked the beginning of a new era for Denmark where the power of the king was limited by a written constitution creating a balance between the executive legislative and judicial branches of government Additionally the design of the palace itself reflects this shift towards modernity incorporating elements of neoclassical architecture while still paying homage to traditional Danish styles\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 51.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 454.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 39.59 sentences/sec\n",
      "1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.437 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.974 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 636.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 50.66 sentences/sec\n",
      "1950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 734.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 66.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 600.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 48.51 sentences/sec\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/data/home/jielinq/miniconda3/envs/openflamingo/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.653 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.232 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 66.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 566.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 48.10 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_4069795/3282533479.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2001,50):\n",
    "    \n",
    "    print(i)\n",
    "    GT_answer = old_tsv.loc[i,'answer']\n",
    "    generated_answer = get_result(old_tsv.loc[i,'image_path'], old_tsv.loc[i,'question'])\n",
    "    rouge1_res, rouge2_res, rougeL_res, bleu4_res, meteor_res, cider_res, spice_res, bertscore_res = answer_evaluation(GT_answer, generated_answer)\n",
    "    \n",
    "    df_results = df_results.append({'GT_answer':GT_answer, 'generated_answer': generated_answer, 'rouge1':rouge1_res, 'rouge2':rouge2_res,'rougeL':rougeL_res, \\\n",
    "                                        'bleu4':bleu4_res, 'meteor':meteor_res, \\\n",
    "                                        'cider':cider_res, 'spice':spice_res, 'bertscore':bertscore_res}, ignore_index=True)\n",
    "    \n",
    "df_results.to_csv('openflamingo_landmark.tsv', sep='\\t', encoding='utf-8', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb36e5e-e5d6-4853-a36b-7c20228acfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca6e5f-a11d-45db-8264-e54764a259bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78972408-8b2f-4ad5-8fc1-2de9e90857d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openflamingo",
   "language": "python",
   "name": "openflamingo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
